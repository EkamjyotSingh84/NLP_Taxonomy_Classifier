{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177e00f-5790-46ca-9d51-75825d921193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('TimSchopf/nlp_taxonomy_classifier')\n",
    "model = BertForSequenceClassification.from_pretrained('TimSchopf/nlp_taxonomy_classifier')\n",
    "\n",
    "# Example Data\n",
    "papers = [\n",
    "    {'title': 'Attention Is All You Need', 'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...'},\n",
    "    {'title': 'SimCSE: Simple Contrastive Learning of Sentence Embeddings', 'abstract': 'This paper presents SimCSE, a simple contrastive learning framework...'}\n",
    "]\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_papers(papers):\n",
    "    # Concatenate title and abstract with a separator token\n",
    "    title_abs = [d['title'] + tokenizer.sep_token + (d.get('abstract') or '') for d in papers]\n",
    "    return title_abs\n",
    "\n",
    "# Convert papers to dataset format\n",
    "class PapersDataset(Dataset):\n",
    "    def __init__(self, papers, tokenizer, max_length=512):\n",
    "        self.papers = papers\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.papers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paper = self.papers[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            paper,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze()\n",
    "        }\n",
    "\n",
    "# Function to predict NLP concepts\n",
    "def predict_nlp_concepts(model, tokenizer, papers, batch_size=8, device='cpu'):\n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = PapersDataset(papers, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Get predicted labels (Assuming logits are probabilities)\n",
    "            preds = torch.sigmoid(logits).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Extended functionality or improvements\n",
    "def extended_predict_nlp_concepts(model, tokenizer, papers, batch_size=8, device='cpu'):\n",
    "    # Preprocess papers and prepare dataset\n",
    "    title_abs = preprocess_papers(papers)\n",
    "    dataset = PapersDataset(title_abs, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Use a threshold for binary classification (e.g., 0.5)\n",
    "            preds = (torch.sigmoid(logits) > 0.5).cpu().numpy()\n",
    "            all_predictions.extend(preds)\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "# Contribution Code\n",
    "def evaluate_model(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance by calculating metrics like accuracy, precision, recall, and F1 score.\n",
    "    Args:\n",
    "    - predictions (list of numpy arrays): Model predictions\n",
    "    - true_labels (list of lists): True labels\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    # Flatten lists for metric calculations\n",
    "    y_true = [label for sublist in true_labels for label in sublist]\n",
    "    y_pred = [pred for sublist in predictions for pred in sublist]\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "        'f1_score': f1_score(y_true, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example usage\n",
    "title_abs = preprocess_papers(papers)\n",
    "predictions = extended_predict_nlp_concepts(model, tokenizer, title_abs)\n",
    "true_labels = [[1, 0], [0, 1]]  # Replace with actual true labels\n",
    "metrics = evaluate_model(predictions, true_labels)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "print(f\"F1 Score: {metrics['f1_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054988db-db5e-4358-aeaf-fe4781a69509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
